{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398b6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "437a0d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "df = pd.read_csv('employee_attrition_dataset.csv')\n",
    "print(\"Dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53cb0eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n",
      "--- Label Encoding ---\n",
      "  Renamed encoded 'Gender' column to 'Gender_Male'.\n",
      "\n",
      "--- One-Hot Encoding ---\n",
      "  One-Hot Encoding applied to: ['Department']\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data ---\n",
    "df = pd.read_csv('employee_attrition_dataset.csv')\n",
    "print(\"Dataset loaded.\")\n",
    "\n",
    "# --- PREPARATION ---\n",
    "\n",
    "df_prepared = df.drop('Employee_ID', axis=1)\n",
    "\n",
    "# --- Label Encoding ---\n",
    "columns_to_encode = ['Attrition', 'Gender']\n",
    "label_encoder_attrition = LabelEncoder() \n",
    "label_encoder_gender = LabelEncoder()\n",
    "\n",
    "print(\"--- Label Encoding ---\")\n",
    "# Encode Attrition\n",
    "original_values = df_prepared['Attrition'].unique()\n",
    "df_prepared['Attrition'] = label_encoder_attrition.fit_transform(df_prepared['Attrition'])\n",
    "encoded_values = df_prepared['Attrition'].unique()\n",
    "mapping = dict(zip(label_encoder_attrition.classes_, label_encoder_attrition.transform(label_encoder_attrition.classes_)))\n",
    "\n",
    "# Encode Gender\n",
    "original_values = df_prepared['Gender'].unique()\n",
    "df_prepared['Gender'] = label_encoder_gender.fit_transform(df_prepared['Gender'])\n",
    "encoded_values = df_prepared['Gender'].unique()\n",
    "mapping = dict(zip(label_encoder_gender.classes_, label_encoder_gender.transform(label_encoder_gender.classes_)))\n",
    "\n",
    "# Rename the encoded column to Gender_Male IF Male is encoded as 1\n",
    "if 'Male' in mapping and mapping['Male'] == 1:\n",
    "        df_prepared.rename(columns={'Gender': 'Gender_Male'}, inplace=True)\n",
    "        print(\"  Renamed encoded 'Gender' column to 'Gender_Male'.\")\n",
    "elif 'Female' in mapping and mapping['Female'] == 1:\n",
    "        # If Female is 1, we need to flip the bits to get Gender_Male (where Male=1)\n",
    "        print(\"  Adjusting 'Gender' encoding to create 'Gender_Male' (Male=1).\")\n",
    "        df_prepared['Gender_Male'] = 1 - df_prepared['Gender']\n",
    "        df_prepared.drop('Gender', axis=1, inplace=True) \n",
    "\n",
    "\n",
    "# --- One-Hot Encoding ---\n",
    "print(\"\\n--- One-Hot Encoding ---\")\n",
    "columns_to_encode_onehot = ['Department'] # Job_Role, Marital_Status removed\n",
    "columns_exist_for_onehot = [col for col in columns_to_encode_onehot if col in df_prepared.columns]\n",
    "\n",
    "df_prepared = pd.get_dummies(df_prepared, columns=columns_exist_for_onehot, drop_first=False)\n",
    "print(f\"  One-Hot Encoding applied to: {columns_exist_for_onehot}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e139e0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Undersampling ---\n",
      "Original distribution: Majority=811, Minority=189\n",
      "Target undersampling ratio (Majority:Minority): 1.0:1\n",
      "Calculated samples to keep from majority class: 189\n",
      "Final dataset 'Attrition' distribution after undersampling:\n",
      " Attrition\n",
      "1    189\n",
      "0    189\n",
      "Name: count, dtype: int64\n",
      "Final ratio (Majority/Minority): 1.00:1\n"
     ]
    }
   ],
   "source": [
    "# ---Undersampling Implementation ---\n",
    "print(\"\\n--- Performing Undersampling ---\")\n",
    "random_seed = 42\n",
    "\n",
    "undersampling_ratio = 1.0 #MODIFY THIS VALUE TO CONTROL THE LEVEL\n",
    "\n",
    "# Separate majority and minority classes (Attrition: No=0, Yes=1)\n",
    "df_majority = df_prepared[df_prepared.Attrition == 0]\n",
    "df_minority = df_prepared[df_prepared.Attrition == 1]\n",
    "\n",
    "minority_size = len(df_minority)\n",
    "majority_size = len(df_majority)\n",
    "\n",
    "print(f\"Original distribution: Majority={majority_size}, Minority={minority_size}\")\n",
    "print(f\"Target undersampling ratio (Majority:Minority): {undersampling_ratio}:1\")\n",
    "\n",
    "# Calculate the desired number of majority samples based on the minority size and the ratio\n",
    "desired_majority_samples = int(minority_size * undersampling_ratio)\n",
    "# Ensure we don't try to sample more majority samples than actually exist\n",
    "n_samples_majority = min(desired_majority_samples, majority_size)\n",
    "\n",
    "print(f\"Calculated samples to keep from majority class: {n_samples_majority}\")\n",
    "\n",
    "# Undersample the majority class to the calculated size\n",
    "df_majority_undersampled = df_majority.sample(n=n_samples_majority, random_state=random_seed)\n",
    "\n",
    "# Combine the (potentially reduced) minority class with the undersampled majority class\n",
    "df_undersampled = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Shuffle the resulting DataFrame\n",
    "df_undersampled = df_undersampled.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "print(\"Final dataset 'Attrition' distribution after undersampling:\\n\", df_undersampled.Attrition.value_counts())\n",
    "print(f\"Final ratio (Majority/Minority): {len(df_undersampled[df_undersampled.Attrition == 0]) / len(df_undersampled[df_undersampled.Attrition == 1]):.2f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6f8554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Selection (Selecting Specific Features) ---\n",
      "\n",
      "--- Defining Target (y) and Features (X) from Undersampled Data ---\n",
      "Undersample your data? (y / n)\n",
      "\n",
      "--- Splitting Data into Train/Test Sets ---\n"
     ]
    }
   ],
   "source": [
    "# --- START: Feature Selection (Select Specific Features) ---\n",
    "print(\"\\n--- Feature Selection (Selecting Specific Features) ---\")\n",
    "\n",
    "# Define the list of features we want to use for modeling.\n",
    "selected_features = [\n",
    "    'Gender_Male', \n",
    "    'Department_IT', \n",
    "    'Age',\n",
    "    'Years_Since_Last_Promotion',\n",
    "    'Work_Life_Balance',\n",
    "    'Performance_Rating',\n",
    "    'Training_Hours_Last_Year',\n",
    "    'Average_Hours_Worked_Per_Week',\n",
    "    'Absenteeism',\n",
    "    'Job_Involvement'\n",
    "]\n",
    "\n",
    "# --- Define Target (y) and Features (X) from Undersampled Data ---\n",
    "print(\"\\n--- Defining Target (y) and Features (X) from Undersampled Data ---\")\n",
    "target_variable = 'Attrition' \n",
    "print(\"Undersample your data? (y / n)\")\n",
    "ans = input()\n",
    "if ans.lower() == 'y':\n",
    "    y = df_undersampled[target_variable] # Target \n",
    "    X = df_undersampled[selected_features] # Features \n",
    "else:\n",
    "    y = df_prepared[target_variable] # Target \n",
    "    X = df_prepared[selected_features] # Features \n",
    "\n",
    "\n",
    "# --- Train-Test Split ---\n",
    "print(\"\\n--- Splitting Data into Train/Test Sets ---\")\n",
    "test_set_size = 0.20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=test_set_size,\n",
    "    random_state=random_seed,\n",
    "    stratify=y \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b9bc9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scaling Features ---\n",
      "Apply scaling? (y / n)\n"
     ]
    }
   ],
   "source": [
    "# --- START: Preprocessing Before Models (Missing Values, Scaling) ---\n",
    "# 1. Scaling Features\n",
    "print(\"\\n--- Scaling Features ---\")\n",
    "print(\"Apply scaling? (y / n)\")\n",
    "ans = input()\n",
    "if ans.lower() == 'y':\n",
    "    scaler = StandardScaler()\n",
    "    # Fit scaler on the training data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    # Transform both training and test data\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "else:\n",
    "     X_train_scaled = X_train\n",
    "     X_test_scaled = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f335d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- K-Nearest Neighbors (KNN) Classifier (Predicting 'Attrition') ---\n",
      "\n",
      "--- Evaluating KNN Model ---\n",
      "KNN Model Accuracy: 0.4737\n",
      "\n",
      "KNN Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.63      0.55        38\n",
      "           1       0.46      0.32      0.38        38\n",
      "\n",
      "    accuracy                           0.47        76\n",
      "   macro avg       0.47      0.47      0.46        76\n",
      "weighted avg       0.47      0.47      0.46        76\n",
      "\n",
      "\n",
      "KNN Confusion Matrix:\n",
      " [[24 14]\n",
      " [26 12]]\n"
     ]
    }
   ],
   "source": [
    "# --- KNN Model ---\n",
    "if X_train_scaled is not None and y_train is not None:\n",
    "    print(f\"\\n--- K-Nearest Neighbors (KNN) Classifier (Predicting '{target_variable}') ---\")\n",
    "\n",
    "    k_value = 6\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k_value)\n",
    "\n",
    "    knn_model.fit(X_train_scaled, y_train) # Train on scaled data\n",
    "\n",
    "    y_pred_knn = knn_model.predict(X_test_scaled) # Predict on scaled data\n",
    "\n",
    "    print(\"\\n--- Evaluating KNN Model ---\")\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    print(f\"KNN Model Accuracy: {accuracy_knn:.4f}\")\n",
    "    print(\"\\nKNN Classification Report:\\n\", classification_report(y_test, y_pred_knn, zero_division=0))\n",
    "    print(\"\\nKNN Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7175259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gaussian Naive Bayes Classifier (Predicting 'Attrition') ---\n",
      "\n",
      "--- Evaluating Naive Bayes Model ---\n",
      "Naive Bayes Model Accuracy: 0.6053\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59        38\n",
      "           1       0.60      0.63      0.62        38\n",
      "\n",
      "    accuracy                           0.61        76\n",
      "   macro avg       0.61      0.61      0.60        76\n",
      "weighted avg       0.61      0.61      0.60        76\n",
      "\n",
      "\n",
      "Naive Bayes Confusion Matrix:\n",
      " [[22 16]\n",
      " [14 24]]\n"
     ]
    }
   ],
   "source": [
    "# --- Naive Bayes Model ---\n",
    "if X_train_scaled is not None and y_train is not None:\n",
    "    print(f\"\\n--- Gaussian Naive Bayes Classifier (Predicting '{target_variable}') ---\")\n",
    "\n",
    "    nb_model = GaussianNB()\n",
    "\n",
    "    nb_model.fit(X_train_scaled, y_train) # Train on scaled data\n",
    "\n",
    "    y_pred_nb = nb_model.predict(X_test_scaled) # Predict on scaled data\n",
    "\n",
    "    print(\"\\n--- Evaluating Naive Bayes Model ---\")\n",
    "    accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "    print(f\"Naive Bayes Model Accuracy: {accuracy_nb:.4f}\")\n",
    "    print(\"\\nNaive Bayes Classification Report:\\n\", classification_report(y_test, y_pred_nb, zero_division=0))\n",
    "    print(\"\\nNaive Bayes Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82c5a8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Decision Tree Classifier (Predicting 'Attrition') ---\n",
      "\n",
      "--- Evaluating Decision Tree Model ---\n",
      "Decision Tree Model Accuracy: 0.4605\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.47      0.47        38\n",
      "           1       0.46      0.45      0.45        38\n",
      "\n",
      "    accuracy                           0.46        76\n",
      "   macro avg       0.46      0.46      0.46        76\n",
      "weighted avg       0.46      0.46      0.46        76\n",
      "\n",
      "\n",
      "Decision Tree Confusion Matrix:\n",
      " [[18 20]\n",
      " [21 17]]\n"
     ]
    }
   ],
   "source": [
    "# --- Decision Tree Model ---\n",
    "if X_train_scaled is not None and y_train is not None:\n",
    "    print(f\"\\n--- Decision Tree Classifier (Predicting '{target_variable}') ---\")\n",
    "\n",
    "    dt_model = DecisionTreeClassifier(random_state=random_seed, class_weight='balanced')\n",
    "\n",
    "    dt_model.fit(X_train_scaled, y_train) # Train on scaled data\n",
    "\n",
    "    y_pred_dt = dt_model.predict(X_test_scaled) # Predict on scaled data\n",
    "\n",
    "    print(\"\\n--- Evaluating Decision Tree Model ---\")\n",
    "    accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "    print(f\"Decision Tree Model Accuracy: {accuracy_dt:.4f}\")\n",
    "    print(\"\\nDecision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt, zero_division=0))\n",
    "    print(\"\\nDecision Tree Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dfeb534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Classifier (Predicting 'Attrition') ---\n",
      "\n",
      "--- Evaluating Random Forest Model ---\n",
      "Random Forest Model Accuracy: 0.5658\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55        38\n",
      "           1       0.56      0.61      0.58        38\n",
      "\n",
      "    accuracy                           0.57        76\n",
      "   macro avg       0.57      0.57      0.57        76\n",
      "weighted avg       0.57      0.57      0.57        76\n",
      "\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      " [[20 18]\n",
      " [15 23]]\n"
     ]
    }
   ],
   "source": [
    "# --- Random Forest Model ---\n",
    "if X_train_scaled is not None and y_train is not None:\n",
    "    print(f\"\\n--- Random Forest Classifier (Predicting '{target_variable}') ---\")\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state=random_seed, class_weight='balanced')\n",
    "\n",
    "    rf_model.fit(X_train_scaled, y_train) \n",
    "\n",
    "    y_pred_rf = rf_model.predict(X_test_scaled) \n",
    "\n",
    "    print(\"\\n--- Evaluating Random Forest Model ---\")\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f\"Random Forest Model Accuracy: {accuracy_rf:.4f}\")\n",
    "    print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf, zero_division=0))\n",
    "    print(\"\\nRandom Forest Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
